{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHeECpAxLCIH",
        "outputId": "d6e10328-7497-4cd8-c186-445a22b7c823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  First Name Middle Name Last Name  Age Gender  Salary\n",
            "0      James                 Smith   30      M   60000\n",
            "1    Michael        Rose             50      M   70000\n",
            "2     Robert              Williams   42         400000\n",
            "3      Maria        Anne     Jones   38      F  500000\n",
            "4        Jen        Mary     Brown   45   None       0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = [[\"James\",\"\",\"Smith\",30,\"M\",60000],\n",
        "        [\"Michael\",\"Rose\",\"\",50,\"M\",70000],\n",
        "        [\"Robert\",\"\",\"Williams\",42,\"\",400000],\n",
        "        [\"Maria\",\"Anne\",\"Jones\",38,\"F\",500000],\n",
        "        [\"Jen\",\"Mary\",\"Brown\",45,None,0]]\n",
        "columns=['First Name','Middle Name','Last Name','Age','Gender','Salary']\n",
        "\n",
        "# Create the pandas DataFrame\n",
        "pandasDF=pd.DataFrame(data=data, columns=columns)\n",
        "\n",
        "# print dataframe.\n",
        "print(pandasDF)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "EA7vd2_BLgTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "               .appName('SparkByExamples.com') \\\n",
        "               .getOrCreate()\n",
        "\n",
        "data = [(\"James\",\"\",\"Smith\",30,\"M\",60000),\n",
        "        (\"Michael\",\"Rose\",\"\",50,\"M\",70000),\n",
        "        (\"Robert\",\"\",\"Williams\",42,\"\",400000),\n",
        "        (\"Maria\",\"Anne\",\"Jones\",38,\"F\",500000),\n",
        "        (\"Jen\",\"Mary\",\"Brown\",45,\"F\",0)]\n",
        "\n",
        "columns = [\"first_name\",\"middle_name\",\"last_name\",\"Age\",\"gender\",\"salary\"]\n",
        "pysparkDF = spark.createDataFrame(data = data, schema = columns)\n",
        "pysparkDF.printSchema()\n",
        "pysparkDF.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCToqJMoLeeD",
        "outputId": "bc98857f-1636-4b7d-8cfd-12232ee9a1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- middle_name: string (nullable = true)\n",
            " |-- last_name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+----------+-----------+---------+---+------+------+\n",
            "|first_name|middle_name|last_name|Age|gender|salary|\n",
            "+----------+-----------+---------+---+------+------+\n",
            "|James     |           |Smith    |30 |M     |60000 |\n",
            "|Michael   |Rose       |         |50 |M     |70000 |\n",
            "|Robert    |           |Williams |42 |      |400000|\n",
            "|Maria     |Anne       |Jones    |38 |F     |500000|\n",
            "|Jen       |Mary       |Brown    |45 |F     |0     |\n",
            "+----------+-----------+---------+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PySpark supports SQL queries to run transformations.\n",
        "#All you need to do is create a Table/View from the PySpark DataFrame.\n",
        "\n",
        "pysparkDF.createOrReplaceTempView(\"Employee\")\n",
        "spark.sql(\"select * from Employee where salary > 100000\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7m_DZanMm2G",
        "outputId": "ff0d255a-c0c8-4d1f-a3c5-603f7dc8f60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+---------+---+------+------+\n",
            "|first_name|middle_name|last_name|Age|gender|salary|\n",
            "+----------+-----------+---------+---+------+------+\n",
            "|    Robert|           | Williams| 42|      |400000|\n",
            "|     Maria|       Anne|    Jones| 38|     F|500000|\n",
            "+----------+-----------+---------+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create PySpark DataFrame from Pandas\n",
        "pysparkDF2 = spark.createDataFrame(pandasDF)\n",
        "pysparkDF2.printSchema()\n",
        "pysparkDF2.show()\n"
      ],
      "metadata": {
        "id": "upbyBGzfNTas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert PySpark to Pandas\n",
        "pandasDF = pysparkDF.toPandas()\n",
        "print(pandasDF)"
      ],
      "metadata": {
        "id": "wtgX5iqPNYpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.readStream.format(\"socket\").option(\"host\",\"localhost\").option(\"port\",\"9090\") .load()"
      ],
      "metadata": {
        "id": "ddnqn_ojQ4Vd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}