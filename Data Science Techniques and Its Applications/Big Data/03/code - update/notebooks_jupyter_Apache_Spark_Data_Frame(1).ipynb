{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|player_api_id|\n",
      "+-------------+\n",
      "|505942       |\n",
      "|155782       |\n",
      "|162549       |\n",
      "|30572        |\n",
      "|23780        |\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "def workwithdf(spark):\n",
    "  # Loading DataFrames: CSV method 1 using spark.read.csv('path')\n",
    "  player_df =spark.read.option('header', True).\n",
    "    option('inferSchema', True).csv('gs://dataproc-staging-us-central1-558853654924-mop7md33/notebooks/\\\n",
    "                                    jupyter/player.csv')\n",
    "\n",
    "  \n",
    "  # Selecting multiple columns\n",
    "  df = player_df.select('player_api_id')\n",
    "  df.show(5,False)\n",
    "\n",
    "  \n",
    "  \n",
    "#   # Add and update columns # notes Spark withColumn() is a DataFrame function that is used to add a new column to DataFrame, change the value of an existing column, convert the datatype of a column, derive a new column from an existing column\n",
    "  \n",
    "#   player_df = player_df.withColumn(\"country\", lit(\"USA\"))\n",
    "#   player_df = player_df.withColumn(\"height\", col('height')/2.54)\n",
    "  \n",
    "#   # Rename columns #notes Spark has a withColumnRenamed() function on DataFrame to change a column name. This is the most straight forward approach; this function takes two parameters; the first is your existing column name and the second is the new column name you wish for.\n",
    "#   player_df.withColumnRenamed('height', 'height_in_cms')\n",
    "  \n",
    "#   # Drop columns \n",
    "  \n",
    "#   player_df = player_df.drop('id', 'player_fifa_api_id')\n",
    "#   player_df.columns\n",
    "  \n",
    "#   player_attr_df = player_attr_df.drop(\n",
    "#     'id', \n",
    "#     'player_fifa_api_id', \n",
    "#     'preferred_foot',\n",
    "#     'attacking_work_rate',\n",
    "#     'defensive_work_rate',\n",
    "#     'crossing',\n",
    "#     'jumping',\n",
    "#     'sprint_speed',\n",
    "#     'balance',\n",
    "#     'aggression',\n",
    "#     'short_passing',\n",
    "#     'potential'\n",
    "#    )\n",
    "#   player_attr_df.columns\n",
    "  \n",
    "#   # When and otherwise \n",
    "#   player_df = player_df.withColumn(\"region\", when(col(\"country\") == \"USA\",\"North America\").otherwise(\"Unknown\"))\n",
    "  \n",
    "#   # Where and Filter\n",
    "  \n",
    "#   # Distinct\n",
    "  \n",
    "#   player_attr_df.select('player_api_id')\\\n",
    "#                    .distinct()\\\n",
    "#                    .count()\n",
    "  \n",
    "#   # Sort\n",
    " \n",
    "#   player_df = player_df.orderBy('player_api_id')\n",
    "#   player_df.show(5, False)\n",
    "  \n",
    "#   # Aggregation\n",
    "  \n",
    "#   player_attr_df = player_attr_df.groupBy('player_api_id')\\\n",
    "#                        .agg({\n",
    "#                            'finishing':\"avg\",\n",
    "#                            \"shot_power\":\"avg\",\n",
    "#                            \"acceleration\":\"avg\"\n",
    "#                        })\n",
    "  \n",
    "#   # join\n",
    "  \n",
    "#   join_df = player_df.join( player_attr_df, player_df.player_api_id == player_attr_df.player_api_id , 'inner')\n",
    " \n",
    "  \n",
    "#   # partitioning \n",
    "#   # No.1 repartition() & coalesce()\n",
    "#   # No. 2 partitionBy()\n",
    "#   join_df = join_df.repartition(4)\n",
    "  \n",
    "#   '''df.write.option(\"header\",True) \\\n",
    "#             .partitionBy(\"year\") \\\n",
    "#             .mode(\"overwrite\") \\\n",
    "#             .csv(\"/tmp/zipcodes-state\")\n",
    "#    '''\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "  spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Analyzing soccer players\") \\\n",
    "    .getOrCreate()\n",
    "  \n",
    "  workwithdf(spark)\n",
    "  \n",
    "  spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}