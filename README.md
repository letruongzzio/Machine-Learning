# Machine Learning

This is where I store the basic knowledge about Machine Learning that I have learned and collected in different books and courses. Below is the main content:

## 1. Introduction to Machine Learning

An overview of Machine Learning along with practicing Python coding to store files and images. In addition, we will practice a project on predicting house prices to better understand ML and will code a bit about matrix derivatives using Numerical Analysis.

## 2. Linear Regression and Overfitting

Focusing on the principles and practical applications of linear regression. It introduces essential concepts such as the cost function, which is crucial for optimizing the model's performance by minimizing the error between predicted and actual values. The chapter also addresses the issue of overfitting, where a model learns too much from the training data, resulting in poor generalization to new data. Supporting Python scripts and utilities facilitate hands-on exercises with both univariate and multivariate datasets, while the provided data files enable practical implementation of linear regression techniques using popular libraries like SciPy and Scikit-learn. Overall, this chapter combines theoretical insights with practical coding exercises to enhance understanding of linear regression and its challenges.

## 3. Overview of clustering algorithms

This chapter provides an overview of various clustering algorithms, focusing on the K-means clustering algorithm and its applications. It covers essential concepts, such as how to prepare data for clustering, and includes practical implementations using Jupyter notebooks, particularly for K-means clustering and K-Nearest Neighbors algorithms. The chapter emphasizes the importance of clustering in unsupervised learning, showcasing various methods to evaluate clustering performance and visualizing the clustering process.

## 4. Neural Networks

Introducing the fundamentals of neural networks, covering key topics such as gradient descent, logistic regression, and the perceptron learning algorithm. It highlights the architecture of neural networks and how they learn from data. Practical examples are provided in Jupyter notebooks, focusing on the softmax regression technique, backpropagation, and various types of neural networks. The chapter serves as a comprehensive guide to understanding the principles and applications of neural networks in machine learning.

## 5. Recommendation Systems

This chapter includes key files related to recommendation techniques, such as "Content-based Recommendation," "Matrix factorization on collaborative filtering," and "Neighborhood-based collaborative filtering." The chapter likely focuses on algorithms for making personalized suggestions based on user data and item similarities.

## 6. Dimensionality Reduction

"Dimensionality Reduction," involves files like "Principal component analysis," "Singular value decomposition," and some images related to structures (e.g., "building2.jpg") and other graphics. This chapter likely covers mathematical techniques to reduce the number of variables in datasets, focusing on methods to retain important information while simplifying the data structure.

## 7. Support Vector Machines

*...Update later...*

## 8. Ensemble Learning and Random Forests

*...Update later...*
___

## **References:**

$[1].$ Vũ Hữu Tiệp. (2018). _Machine Learning cơ bản_. Nhà xuất bản Khoa học và Kỹ thuật.

$[2].$ Géron, A. (2023). *Hands-On Machine Learning with SciKit-Learn*, Keras & TensorFlow (3rd ed.). O’Reilly Media.

$[3].$ DeepLearning.AI, Andrew Ng. _Machine Learning Specialization_.

$[4].$ Deisenroth, M.P., Faisal, A.A., and Ong, C.S. (2020). *Mathematics for Machine Learning*. Cambridge University Press. ISBN: 9781108470049. Available at: https://books.google.com.vn/books?id=pFjPDwAAQBAJ.
